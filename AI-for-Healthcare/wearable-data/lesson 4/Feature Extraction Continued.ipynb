{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "\n",
    "import activity_classifier_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 256\n",
    "data = activity_classifier_utils.LoadWristPPGDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "Time Domain:\n",
    "* mean\n",
    "* std\n",
    "* 5, 10, 15, 20, 25 percentile\n",
    "* cross-correlation of all pairs of channels\n",
    "* total energy\n",
    "\n",
    "Frequency Domain:\n",
    "* dominant frequency\n",
    "* fraction of energy in each 1Hz bin from 0 to 6 Hz\n",
    "* spectral entropy of each channel - i'll do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low-pass filter at 12 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LowpassFilter(signal, fs):\n",
    "    b, a = sp.signal.butter(3, 12, btype='lowpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Featurize(accx, accy, accz, fs):\n",
    "    \"\"\"A partial featurization of the accelerometer signal.\n",
    "    \n",
    "    Args:\n",
    "        accx: (np.array) x-channel of the accelerometer.\n",
    "        accy: (np.array) y-channel of the accelerometer.\n",
    "        accz: (np.array) z-channel of the accelerometer.\n",
    "        fs: (number) the sampling rate of the accelerometer\n",
    "        \n",
    "    Returns:\n",
    "        n-tuple of accelerometer features\n",
    "    \"\"\"\n",
    "    \n",
    "    accx = LowpassFilter(accx, fs)\n",
    "    accy = LowpassFilter(accy, fs)\n",
    "    accz = LowpassFilter(accz, fs)\n",
    "    \n",
    "    # The mean of the x-channel\n",
    "    mn_x = np.mean(accx)\n",
    "\n",
    "    # The standard deviation of the x-channel\n",
    "    std_x = np.std(accx)\n",
    "\n",
    "    # The 5th percentile of the x-channel\n",
    "    p5_x = np.percentile(accx, 5)\n",
    "\n",
    "    # The pearson correlation coefficient between the x and y channels\n",
    "    corr_xy = sp.stats.pearsonr(accx, accy)[0]\n",
    "\n",
    "    # The total AC energy of the x-axis\n",
    "    energy_x = np.sum(np.square(accx - np.mean(accx)))  # np.var(accx) * len(accx)\n",
    "    \n",
    "    # Take an FFT of the signal. If the signal is too short, 0-pad it so we have at least 2046 points in the FFT.\n",
    "    fft_len = max(len(accx), 2046)\n",
    "    \n",
    "    # Create an array of frequency bins\n",
    "    freqs = np.fft.rfftfreq(fft_len, 1 / fs)\n",
    "    \n",
    "    # Take an FFT of the centered signal\n",
    "    fft_x = np.fft.rfft(accx - np.mean(accx), fft_len)\n",
    "    \n",
    "    # The frequency with the most power between 0.25 and 12 Hz\n",
    "    low_freqs = (freqs >= 0.25) & (freqs <= 12)\n",
    "    dominant_frequency_x = freqs[low_freqs][np.argmax(np.abs(fft_x)[low_freqs])]\n",
    "\n",
    "    # The fraction of energy between 2 and 3 Hz in the x-channel\n",
    "    spectral_energy_x = np.square(np.abs(fft_x))\n",
    "    energy_23_x = (np.sum(spectral_energy_x[(freqs >= 2) & (freqs <= 3)])\n",
    "                   / np.sum(spectral_energy_x))\n",
    "    \n",
    "    return (mn_x,\n",
    "            std_x,\n",
    "            p5_x,\n",
    "            corr_xy,\n",
    "            energy_x,\n",
    "            dominant_frequency_x,\n",
    "            energy_23_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of features, because we have to compute each of these for all channels. I've spared you that effort and put all the features in `activity_classifier_utils.py`. Poke through that file now to see the feature extraction code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Now we can extract the features for all of our data.\n",
    "\n",
    "Train on 10 second long non-overlapping windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length_s = 10\n",
    "window_shift_s = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = window_length_s * fs\n",
    "window_shift = window_shift_s * fs\n",
    "labels, subjects, features = [], [], []\n",
    "for subject, activity, df in data:\n",
    "    for i in range(0, len(df) - window_length, window_shift):\n",
    "        window = df[i: i + window_length]\n",
    "        accx = window.accx.values\n",
    "        accy = window.accy.values\n",
    "        accz = window.accz.values\n",
    "        features.append(activity_classifier_utils.Featurize(accx, accy, accz, fs=fs))\n",
    "        labels.append(activity)\n",
    "        subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "subjects = np.array(subjects)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with 10 seconds of 256 Hz accelerometer data. That's 2500 samples per channel, and for three channel that's 7500 points. We've successfully reduced these 7500 points to just 55 points while hopefully retaining all the information we need to build a good classifier.\n",
    "\n",
    "Although we only have 8 subjects of data, we have 611 datapoints because each 10 second window is its own datapoint. However, our datapoints are not independent. Because there's homogeneity in how individuals do an activity, datapoints from the same person might be more similar to each other. We have to keep this in mind when we train and evaluate our model. In the next video we'll use these features to build a random forest model and classify our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
